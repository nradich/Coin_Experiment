{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependencies \n",
    "#had to \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from requests import Request, Session\n",
    "from requests.exceptions import ConnectionError, Timeout, TooManyRedirects\n",
    "import json\n",
    "import config \n",
    "from coincallandwritepythonfile import refined_coin_list, injest_date, write_to_storage, convert_dataframe_to_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure no blank id values for query\n",
    "refined_coin_list = refined_coin_list[refined_coin_list['id'] != \"\"]\n",
    "#get ids for each coin and convert to list\n",
    "coin_ids = refined_coin_list.id.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_coin_ids = len(coin_ids)\n",
    "#max number is 30 per minute for the API\n",
    "number_of_queries_per_run = 25\n",
    "rounded_up = np.ceil(number_of_coin_ids/ number_of_queries_per_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Make_Call (id, api_key):\n",
    "    url = 'https://pro-api.coinmarketcap.com/v2/cryptocurrency/quotes/latest'\n",
    "    parameters = {\n",
    "        'id': id,\n",
    "                }\n",
    "    headers = {\n",
    "    'Accepts': 'application/json',\n",
    "    'X-CMC_PRO_API_KEY': api_key\n",
    "    }\n",
    "\n",
    "    #make API call and return response as a dictionary\n",
    "    session = Session()\n",
    "    session.headers.update(headers)\n",
    "    response = session.get(url, params=parameters)\n",
    "    data = json.loads(response.text)\n",
    "    #erroring on 'Data' sometimes, like a rogue id\n",
    "    #erroring because can't make more than 30 calls per minute \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "  \n",
    "#schedule.run_all(delay_seconds= 3).do(func)\n",
    "def get_coin_info_breakup(list_of_coins_, api_key):\n",
    "    \"\"\"Function makes API call for each coin ID within list of coins.\n",
    "    Designed to take list from top 100 coins and get their most recent price information. \"\"\"\n",
    "\n",
    "    #create an empty dataframe that we will append responses too\n",
    "    df = pd.DataFrame()\n",
    "    #a count variable to index the respones when trying to concat \n",
    "    #get parameters for API call\n",
    "    number_of_coin_ids = len(list_of_coins_)\n",
    "    #max number is 30 per minute for the API\n",
    "    number_of_queries_per_run = 25\n",
    "    rounded_up = np.ceil(number_of_coin_ids/ number_of_queries_per_run)\n",
    "    coin_array = list_of_coins_\n",
    "    test = np.array_split(coin_array,rounded_up)\n",
    "    count =0\n",
    "    #schedule.every(60).seconds.do(Make_Call(id, api_key))\n",
    "    while count < rounded_up:\n",
    "        for id in test[count]:\n",
    "            try:\n",
    "                data = Make_Call(id, api_key)\n",
    "                cmc_df = pd.DataFrame.from_dict(data['data'], orient='index')\n",
    "\n",
    "                #expand nested quote column containing price information\n",
    "                expanded_df = pd.DataFrame.from_dict(cmc_df['quote'][0], orient= 'index')     \n",
    "                #set then index for count ie the number of runs \n",
    "                expanded_df.set_index(pd.Index([count]),inplace= True)\n",
    "\n",
    "                #dropping nested columns that we won't explore during this exercise\n",
    "                trial = cmc_df.drop(['quote','tags', 'platform'], axis= 1)\n",
    "                \n",
    "                #setting index as count variable so can join back\n",
    "                trial.set_index(pd.Index([count]),inplace= True)\n",
    "                \n",
    "                #concat was tricky had to add\n",
    "                #had to add key to get them to append properly\n",
    "                coin_price_df = pd.concat([trial,expanded_df], axis=1, keys=['trial', 'expanded_df']  )\n",
    "                #coin_price_df.reset_index(drop = True, inplace= True)\n",
    "                coin_price_merge = pd.merge(trial, expanded_df)\n",
    "                #this saves it as a coreframe\n",
    "\n",
    "                    \n",
    "                df = df.append(coin_price_merge) \n",
    "            except KeyError:\n",
    "                continue\n",
    "            \n",
    "            #parse dict and load in relavant data to a DF\n",
    "        time.sleep(60)\n",
    "        count += 1\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_coin_info_breakup(coin_ids,  config.coin_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to storage function takes dataset input as a CSV so had to convert\n",
    "df[\"File_Name\"] = \"Coin_Price_Fact\"\n",
    "#Add column for injested at \n",
    "df[\"injest_datetime\"] = injest_date\n",
    "#convert to CSV to write to storage\n",
    "df_csv = convert_dataframe_to_file(df, \"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the new DF to storage\n",
    "storage_account_name = config.storage_account_name\n",
    "storage_account_key = config.storage_account_key\n",
    "container_name = \"coinprice\"\n",
    "directory_name = \"raw\"\n",
    "\n",
    "dataframe = write_to_storage(storage_account_name=storage_account_name, storage_account_key= storage_account_key, container_name= container_name, directory_name= directory_name,\\\n",
    "    dataset = df_csv, file_name= \"coinprice.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refine dataset to write to refined ADLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove null values\n",
    "dataframe = dataframe[dataframe.name.notnull()]\n",
    "price_and_supply_columns = ['id', 'name', 'symbol','price', 'max_supply', 'circulating_supply', \\\n",
    "   'total_supply', 'market_cap','File_Name', 'injest_datetime']\n",
    "volume_and_percent_change_columns = ['id', 'volume_24h', 'volume_change_24h', 'percent_change_1h', 'percent_change_24h',\n",
    "       'percent_change_7d', 'percent_change_30d', 'percent_change_60d',\n",
    "       'percent_change_90d','File_Name', 'injest_datetime']\n",
    "\n",
    "\n",
    "df_price_and_supply = dataframe[price_and_supply_columns]\n",
    "df_price_and_supply_csv= convert_dataframe_to_file(df_price_and_supply, \"csv\")\n",
    "\n",
    "df_volume_and_percent_change = dataframe[volume_and_percent_change_columns]\n",
    "df_volume_and_percent_change_csv = convert_dataframe_to_file(df_volume_and_percent_change, \"csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the new DF to storage\n",
    "storage_account_name = config.storage_account_name\n",
    "storage_account_key = config.storage_account_key\n",
    "container_name_price = \"coinprice\"\n",
    "directory_name = \"refined\"\n",
    "\n",
    "container_name_volume = \"coinvolume\"\n",
    "\n",
    "df_volume_and_percent_change_csv\n",
    "df_price_and_supply_csv\n",
    "\n",
    "dataframe_price_supply = write_to_storage(storage_account_name=storage_account_name, storage_account_key= storage_account_key,\\\n",
    "     container_name= container_name_price, directory_name= directory_name,\\\n",
    "    dataset = df_price_and_supply_csv, file_name= \"coinpricerefined.csv\")\n",
    "\n",
    "dataframe_price_supply = write_to_storage(storage_account_name=storage_account_name, storage_account_key= storage_account_key,\\\n",
    "     container_name= container_name_volume, directory_name= directory_name,\\\n",
    "    dataset = df_volume_and_percent_change_csv, file_name= \"coinvolumefined.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "58a687088a3261ce9df5dee3177c51a1c9f11335b27c4c9154772790953dd213"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
