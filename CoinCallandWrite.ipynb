{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Depedencies\n",
                "import pandas as pd \n",
                "from requests import Request, Session\n",
                "from requests.exceptions import ConnectionError, Timeout, TooManyRedirects\n",
                "import json\n",
                "import config \n",
                "api_key = config.coin_api_key\n",
                "#get the current datetime to add to the file\n",
                "from datetime import datetime\n",
                "now = datetime.now()\n",
                "injest_date = now.strftime(\"%m/%d/%Y %H:%M:%S\")\n",
                "filedate = now.strftime(\"%m/%d/%Y\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "#API call to CoinMarketCap\n",
                "def api_mapping_call(number_of_entries, api_key ):\n",
                "  url = 'https://pro-api.coinmarketcap.com/v1/cryptocurrency/map'\n",
                "  parameters = {\n",
                "      'listing_status':'active',\n",
                "      'limit': number_of_entries,\n",
                "      'sort': 'cmc_rank'\n",
                "  }\n",
                "  headers = {\n",
                "    'Accepts': 'application/json',\n",
                "    'X-CMC_PRO_API_KEY': api_key\n",
                "  }\n",
                "\n",
                "  session = Session()\n",
                "  session.headers.update(headers)\n",
                "  response = session.get(url, params=parameters)\n",
                "  data = json.loads(response.text)\n",
                "  return data\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "data = api_mapping_call(100, api_key)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [],
            "source": [
                "#grabs section of dictionary \n",
                "cmc_data = data['data']\n",
                "#puts the dict into a DF, now need to expand nested platform column\n",
                "cmc_df = pd.DataFrame.from_dict(cmc_data, orient='columns')\n",
                "#expand nest columns\n",
                "expanded_df = cmc_df['platform'].apply(pd.Series)\n",
                "#extract columns names\n",
                "cols = expanded_df.columns\n",
                "#modify column names to new names\n",
                "cols_new = [x + \"_expanded\" for x in cols]\n",
                "#create a dict mapping with old to new names\n",
                "mapping = {key1: key2 for key1, key2 in zip(cols, cols_new)}\n",
                "#implement and rename columns \n",
                "expanded_df = expanded_df.rename(columns=mapping)\n",
                "#expanded Dataframe, when expanding duplicate columns come into play ie 2 ID columns\n",
                "top_coins_df = pd.concat([cmc_df.drop(['platform'], axis= 1),expanded_df], axis= 1 )\n",
                "#add column file name\n",
                "top_coins_df[\"File_Name\"] = \"Coin_Ranking_Dim\"\n",
                "#Add column for injested at \n",
                "top_coins_df[\"injest_datetime\"] = injest_date\n",
                "#turn dataframe to CSV\n",
                "top_coins_csv = top_coins_df.to_csv(index = False )\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                " - write DF to parquet format\n",
                " `trial_write_to_parquet = test.to_parquet(headers = 'none')`\n",
                " - write DF to CSV format\n",
                "`dfasCSV = test.to_csv()`\n",
                " - write DF to string format\n",
                "`dfAsString = test.to_string(header=False, index=False)`\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "#this works, needed to send it as text !!\n",
                "#it works too, had to save it as a CSV\n",
                "from azure.storage.filedatalake import DataLakeServiceClient\n",
                "# install the following package \n",
                "# pip install azure-storage-file-datalake \n",
                "# Get the below details from your storage account\n",
                "storage_account_name = config.storage_account_name\n",
                "storage_account_key = config.storage_account_key\n",
                "container_name = \"newcontainer\"\n",
                "directory_name = \"testingtoo\"\n",
                "\n",
                "def write_to_storage(storage_account_name,storage_account_key, container_name, directory_name,dataset,  file_name):\n",
                "    \"\"\"Function to write dataframe to storage. Specicify storage account name, storage account key, container name, directory name and file name.\n",
                "    The fuction will check if container already exists, if it doesn't it will create a new container. If the already exisits, it will write the file to the specified container.\n",
                "    Dataset must be saved as specified file type(csv,txt,parquet)\n",
                "    File name must end in specificed file type (csv, txt, parquet).\"\"\"\n",
                "\n",
                "    #convert dataset input to pandas DF\n",
                "    df = pd.DataFrame([x.split(',') for x in dataset.split('\\r\\n')])\n",
                "    #promote first row to headers\n",
                "    df= df.rename(columns=df.iloc[0]).drop(df.index[0])\n",
                "    \n",
                "\n",
                "    service_client = DataLakeServiceClient(account_url=\"{}://{}.dfs.core.windows.net\".format(\n",
                "            \"https\", storage_account_name), credential=storage_account_key)\n",
                "    try:\n",
                "        file_system_client = service_client.create_file_system(file_system=container_name)\n",
                "        dir_client = file_system_client.get_directory_client(directory_name)\n",
                "        dir_client.create_directory()\n",
                "        #set data to appropriate dataframe\n",
                "        file = dataset\n",
                "        file_client = dir_client.create_file(file_name)\n",
                "        file_client.append_data(file, 0, len(file))\n",
                "        file_client.flush_data(len(file))\n",
                "    except  :\n",
                "        #ResourceAlreadyExists\n",
                "        file_system_client = service_client.get_file_system_client(file_system=container_name)\n",
                "        dir_client = file_system_client.get_directory_client(directory_name)\n",
                "        dir_client.create_directory()\n",
                "        #set data to appropriate dataframe\n",
                "        file = dataset\n",
                "        file_client = dir_client.create_file(file_name)\n",
                "        file_client.append_data(file, 0, len(file))\n",
                "        file_client.flush_data(len(file))\n",
                "\n",
                "    \n",
                "\n",
                "\n",
                "    return df\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "dataframe = write_to_storage(storage_account_name=storage_account_name, storage_account_key= storage_account_key, container_name= container_name, directory_name= directory_name,\\\n",
                "    dataset = top_coins_csv, file_name= \"top100coins.csv\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### -----------------------------------------------------------------------------------------------------------------------------------------"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#reset the index\n",
                "#then filter out the blank line, select columns, and write to refined\n",
                "#the blank line isnull...was showing as 'None'\n",
                "#dataframe[dataframe[\"id\"] != \" \"]\n",
                "dataframe.index.is_unique"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Now working on refined dataset\n",
                "## select necessary columns, make sure that id isn't null\n",
                "##write to storage then can reference DF in another script, to pull for each ID\n",
                "## also look into .format for naming of the files so that we can write multiple times "
            ]
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "58a687088a3261ce9df5dee3177c51a1c9f11335b27c4c9154772790953dd213"
        },
        "kernelspec": {
            "display_name": "Python 3.9.7 ('base')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
