{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Depedencies\n",
                "import pandas as pd \n",
                "from requests import Request, Session\n",
                "from requests.exceptions import ConnectionError, Timeout, TooManyRedirects\n",
                "import json\n",
                "import config \n",
                "api_key = config.coin_api_key\n",
                "#get the current datetime to add to the file\n",
                "from datetime import datetime\n",
                "now = datetime.now()\n",
                "injest_date = now.strftime(\"%m/%d/%Y %H:%M:%S\")\n",
                "filedate = now.strftime(\"%m/%d/%Y\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "#API call to CoinMarketCap\n",
                "def api_mapping_call(number_of_entries, api_key ):\n",
                "  url = 'https://pro-api.coinmarketcap.com/v1/cryptocurrency/map'\n",
                "  parameters = {\n",
                "      'listing_status':'active',\n",
                "      'limit': number_of_entries,\n",
                "      'sort': 'cmc_rank'\n",
                "  }\n",
                "  headers = {\n",
                "    'Accepts': 'application/json',\n",
                "    'X-CMC_PRO_API_KEY': api_key\n",
                "  }\n",
                "\n",
                "  session = Session()\n",
                "  session.headers.update(headers)\n",
                "  response = session.get(url, params=parameters)\n",
                "  data = json.loads(response.text)\n",
                "  return data\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "data = api_mapping_call(100, api_key)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "#grabs section of dictionary \n",
                "cmc_data = data['data']\n",
                "#puts the dict into a DF, now need to expand nested platform column\n",
                "cmc_df = pd.DataFrame.from_dict(cmc_data, orient='columns')\n",
                "#expand nest columns\n",
                "expanded_df = cmc_df['platform'].apply(pd.Series)\n",
                "#extract columns names\n",
                "cols = expanded_df.columns\n",
                "#modify column names to new names\n",
                "cols_new = [x + \"_expanded\" for x in cols]\n",
                "#create a dict mapping with old to new names\n",
                "mapping = {key1: key2 for key1, key2 in zip(cols, cols_new)}\n",
                "#implement and rename columns \n",
                "expanded_df = expanded_df.rename(columns=mapping)\n",
                "#expanded Dataframe, when expanding duplicate columns come into play ie 2 ID columns\n",
                "top_coins_df = pd.concat([cmc_df.drop(['platform'], axis= 1),expanded_df], axis= 1 )\n",
                "#add column file name\n",
                "top_coins_df[\"File_Name\"] = \"Coin_Ranking_Dim\"\n",
                "#Add column for injested at \n",
                "top_coins_df[\"injest_datetime\"] = injest_date\n",
                "#turn dataframe to CSV\n",
                "top_coins_csv = top_coins_df.to_csv(index = False )\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                " - write DF to parquet format\n",
                " `trial_write_to_parquet = test.to_parquet(headers = 'none')`\n",
                " - write DF to CSV format\n",
                "`dfasCSV = test.to_csv()`\n",
                " - write DF to string format\n",
                "`dfAsString = test.to_string(header=False, index=False)`\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "#this works, needed to send it as text !!\n",
                "#it works too, had to save it as a CSV\n",
                "from azure.storage.filedatalake import DataLakeServiceClient\n",
                "# install the following package \n",
                "# pip install azure-storage-file-datalake \n",
                "# Get the below details from your storage account\n",
                "storage_account_name = config.storage_account_name\n",
                "storage_account_key = config.storage_account_key\n",
                "container_name = \"coinlist\"\n",
                "directory_name = \"raw\"\n",
                "\n",
                "def write_to_storage(storage_account_name,storage_account_key, container_name, directory_name,dataset,  file_name):\n",
                "    \"\"\"Function to write dataframe to storage. Specicify storage account name, storage account key, container name, directory name and file name.\n",
                "    The fuction will check if container already exists, if it doesn't it will create a new container. If the already exisits, it will write the file to the specified container.\n",
                "    Dataset must be saved as specified file type(csv,txt,parquet)\n",
                "    File name must end in specificed file type (csv, txt, parquet).\"\"\"\n",
                "\n",
                "    #convert dataset input to pandas DF\n",
                "    df = pd.DataFrame([x.split(',') for x in dataset.split('\\r\\n')])\n",
                "    #promote first row to headers\n",
                "    df= df.rename(columns=df.iloc[0]).drop(df.index[0])\n",
                "\n",
                "    #timestamp when function runs\n",
                "    injest_date = now.strftime(\"%m/%d/%Y %H:%M:%S\")\n",
                "    #removed spaces from the datetime, backslashed dictate new folder structure withn ADLS\n",
                "    trimmed_injest_Date = injest_date.replace( \" \", \"_\").replace(' ', '_').replace(\"/\",\"_\")\n",
                "    #split the given file name into file title and file type\n",
                "    file_name_title, file_type = file_name.split('.')\n",
                "    #created storage file as it will appear in ADLS\n",
                "    storage_file = (\"{}_{}.{}\").format(file_name_title, trimmed_injest_Date, file_type)\n",
                "    \n",
                "\n",
                "    service_client = DataLakeServiceClient(account_url=\"{}://{}.dfs.core.windows.net\".format(\n",
                "            \"https\", storage_account_name), credential=storage_account_key)\n",
                "    try:\n",
                "        file_system_client = service_client.create_file_system(file_system=container_name)\n",
                "        dir_client = file_system_client.get_directory_client(directory_name)\n",
                "        dir_client.create_directory()\n",
                "        #set data to appropriate dataframe\n",
                "        file = dataset\n",
                "        file_client = dir_client.create_file(storage_file)\n",
                "        file_client.append_data(file, 0, len(file))\n",
                "        file_client.flush_data(len(file))\n",
                "    except  :\n",
                "        #ResourceAlreadyExists\n",
                "        file_system_client = service_client.get_file_system_client(file_system=container_name)\n",
                "        dir_client = file_system_client.get_directory_client(directory_name)\n",
                "        dir_client.create_directory()\n",
                "        #set data to appropriate dataframe\n",
                "        file = dataset\n",
                "        file_client = dir_client.create_file(storage_file)\n",
                "        file_client.append_data(file, 0, len(file))\n",
                "        file_client.flush_data(len(file))   \n",
                "\n",
                "\n",
                "    return df\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "dataframe = write_to_storage(storage_account_name=storage_account_name, storage_account_key= storage_account_key, container_name= container_name, directory_name= directory_name,\\\n",
                "    dataset = top_coins_csv, file_name= \"top100coins.csv\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### -----------------------------------------------------------------------------------------------------------------------------------------"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "#filters out null names\n",
                "#needed to ensure that dataset was in CSV format\n",
                "#filters out null names\n",
                "dataframe = dataframe[dataframe.name.notnull()]\n",
                "#make column selections\n",
                "desired_columns = [\"id\", \"name\", \"symbol\", \"rank\",\"File_Name\", \"injest_datetime\"]\n",
                "#filter dataset for desired columns\n",
                "refined_dataframe = dataframe[desired_columns]\n",
                "#convert dataframe to CSV to write to storage\n",
                "refined_dataframe_csv = refined_dataframe.to_csv(index = False )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Call function to write to storage and save output dataframe \n",
                "refined_coin_list = write_to_storage(storage_account_name=storage_account_name, storage_account_key= storage_account_key, container_name= \"coinlist\", directory_name= \"refined\",\\\n",
                "    dataset = refined_dataframe_csv, file_name= \"top100coins.csv\")"
            ]
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "58a687088a3261ce9df5dee3177c51a1c9f11335b27c4c9154772790953dd213"
        },
        "kernelspec": {
            "display_name": "Python 3.9.7 ('base')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
