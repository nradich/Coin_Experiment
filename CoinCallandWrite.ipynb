{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Depedencies\n",
                "import pandas as pd \n",
                "from requests import Request, Session\n",
                "from requests.exceptions import ConnectionError, Timeout, TooManyRedirects\n",
                "import json\n",
                "import config \n",
                "api_key = config.coin_api_key"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code EPDMCYMU7 to authenticate.\n"
                    ]
                }
            ],
            "source": [
                "#Code to authenticate notebook \n",
                "import pandas as pd\n",
                "from azure.datalake.store import core, lib, multithread\n",
                "token = lib.auth()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code F4XTUY5GP to authenticate.\n"
                    ]
                },
                {
                    "ename": "DatalakeRESTException",
                    "evalue": "HTTP error: ConnectionError(MaxRetryError(\"HTTPSConnectionPool(host='coinstoragenjr.azuredatalakestore.net', port=443): Max retries exceeded with url: /webhdfs/v1/?OP=LISTSTATUS&api-version=2018-09-01&listSize=4000 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001A3A864A160>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\"))",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mDatalakeRESTException\u001b[0m                     Traceback (most recent call last)",
                        "\u001b[1;32mC:\\Users\\NICHOL~1.RAD\\AppData\\Local\\Temp/ipykernel_27276/175684794.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0madl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAzureDLFileSystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstore_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'coinstoragenjr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0madl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Read a file into pandas dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\azure\\datalake\\store\\core.py\u001b[0m in \u001b[0;36mls\u001b[1;34m(self, path, detail, invalidate_cache)\u001b[0m\n\u001b[0;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m    167\u001b[0m         \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAzureDLPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m         \u001b[0mfiles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minvalidate_cache\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m             \u001b[1;31m# in this case we just invalidated the cache (if it was true), so no need to do it again\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\azure\\datalake\\store\\core.py\u001b[0m in \u001b[0;36m_ls\u001b[1;34m(self, path, invalidate_cache, batch_size)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ls_batched\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pathSuffix'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_posix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\azure\\datalake\\store\\core.py\u001b[0m in \u001b[0;36m_ls_batched\u001b[1;34m(self, path, batch_size)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mcontinuation_token\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m             \u001b[0mls_call_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mazure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'LISTSTATUS'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mls_call_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'FileStatuses'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'FileStatus'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\azure\\datalake\\store\\lib.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, op, path, is_extended, expected_error_code, retry_policy, headers, **kwargs)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mrequest_successful\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlast_exception\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mDatalakeRESTException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'HTTP error: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_exception\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[0mexception_log_level\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mERROR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;31mDatalakeRESTException\u001b[0m: HTTP error: ConnectionError(MaxRetryError(\"HTTPSConnectionPool(host='coinstoragenjr.azuredatalakestore.net', port=443): Max retries exceeded with url: /webhdfs/v1/?OP=LISTSTATUS&api-version=2018-09-01&listSize=4000 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001A3A864A160>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\"))"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "from azure.datalake.store import core, lib, multithread\n",
                "token = lib.auth()\n",
                "# Create an ADLS File System Client. The store_name is the name of your ADLS account\n",
                "adl = core.AzureDLFileSystem(token = token, store_name='coinstoragenjr')\n",
                "\n",
                "adl.ls('')\n",
                "\n",
                "# Read a file into pandas dataframe\n",
                "with adl.open('sampledata2.csv', 'rb') as f:\n",
                "    df = pd.read_csv(f) \n",
                "\n",
                "# Show the dataframe\n",
                "df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "ename": "PermissionError",
                    "evalue": ".",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
                        "\u001b[1;32mC:\\Users\\NICHOL~1.RAD\\AppData\\Local\\Temp/ipykernel_27276/3616338007.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0madl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAzureDLFileSystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstore_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'trial'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0madl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\azure\\datalake\\store\\core.py\u001b[0m in \u001b[0;36mls\u001b[1;34m(self, path, detail, invalidate_cache)\u001b[0m\n\u001b[0;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m    167\u001b[0m         \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAzureDLPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m         \u001b[0mfiles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minvalidate_cache\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m             \u001b[1;31m# in this case we just invalidated the cache (if it was true), so no need to do it again\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\azure\\datalake\\store\\core.py\u001b[0m in \u001b[0;36m_ls\u001b[1;34m(self, path, invalidate_cache, batch_size)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ls_batched\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pathSuffix'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_posix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\azure\\datalake\\store\\core.py\u001b[0m in \u001b[0;36m_ls_batched\u001b[1;34m(self, path, batch_size)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mcontinuation_token\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m             \u001b[0mls_call_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mazure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'LISTSTATUS'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mls_call_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'FileStatuses'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'FileStatus'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\azure\\datalake\\store\\lib.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, op, path, is_extended, expected_error_code, retry_policy, headers, **kwargs)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m403\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_response_and_raise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPermissionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexception_log_level\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m404\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_response_and_raise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexception_log_level\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\azure\\datalake\\store\\lib.py\u001b[0m in \u001b[0;36mlog_response_and_raise\u001b[1;34m(self, response, exception, level)\u001b[0m\n\u001b[0;32m    347\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34mu\"\\n(Response body was truncated)\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_json_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;31mPermissionError\u001b[0m: ."
                    ]
                }
            ],
            "source": [
                "adl = core.AzureDLFileSystem(token = token, store_name='trial')\n",
                "\n",
                "adl.ls('')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "ename": "DatalakeRESTException",
                    "evalue": "HTTP error: ConnectionError(MaxRetryError(\"HTTPSConnectionPool(host='coinstoragenjr.azuredatalakestore.net', port=443): Max retries exceeded with url: /webhdfs/v1/?OP=LISTSTATUS&api-version=2018-09-01&listSize=4000 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001A3A863F520>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\"))",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mDatalakeRESTException\u001b[0m                     Traceback (most recent call last)",
                        "\u001b[1;32mC:\\Users\\NICHOL~1.RAD\\AppData\\Local\\Temp/ipykernel_27276/3863886915.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0madlsFileSystemClient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAzureDLFileSystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstore_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'coinstoragenjr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0madl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAzureDLFileSystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstore_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'coinstoragenjr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0madl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\azure\\datalake\\store\\core.py\u001b[0m in \u001b[0;36mls\u001b[1;34m(self, path, detail, invalidate_cache)\u001b[0m\n\u001b[0;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m    167\u001b[0m         \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAzureDLPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m         \u001b[0mfiles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minvalidate_cache\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m             \u001b[1;31m# in this case we just invalidated the cache (if it was true), so no need to do it again\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\azure\\datalake\\store\\core.py\u001b[0m in \u001b[0;36m_ls\u001b[1;34m(self, path, invalidate_cache, batch_size)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ls_batched\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pathSuffix'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_posix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\azure\\datalake\\store\\core.py\u001b[0m in \u001b[0;36m_ls_batched\u001b[1;34m(self, path, batch_size)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mcontinuation_token\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m             \u001b[0mls_call_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mazure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'LISTSTATUS'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mls_call_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'FileStatuses'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'FileStatus'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\azure\\datalake\\store\\lib.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, op, path, is_extended, expected_error_code, retry_policy, headers, **kwargs)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mrequest_successful\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlast_exception\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mDatalakeRESTException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'HTTP error: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_exception\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[0mexception_log_level\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mERROR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;31mDatalakeRESTException\u001b[0m: HTTP error: ConnectionError(MaxRetryError(\"HTTPSConnectionPool(host='coinstoragenjr.azuredatalakestore.net', port=443): Max retries exceeded with url: /webhdfs/v1/?OP=LISTSTATUS&api-version=2018-09-01&listSize=4000 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001A3A863F520>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\"))"
                    ]
                }
            ],
            "source": [
                "adlsFileSystemClient = core.AzureDLFileSystem(token, store_name='coinstoragenjr')\n",
                "adl = core.AzureDLFileSystem(token, store_name='coinstoragenjr')\n",
                "adl.ls('')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "url = 'https://pro-api.coinmarketcap.com/v1/cryptocurrency/map'\n",
                "parameters = {\n",
                "    'listing_status':'active',\n",
                "    'limit': 100,\n",
                "    'sort': 'cmc_rank'\n",
                "}\n",
                "headers = {\n",
                "  'Accepts': 'application/json',\n",
                "  'X-CMC_PRO_API_KEY': api_key\n",
                "}\n",
                "\n",
                "session = Session()\n",
                "session.headers.update(headers)\n",
                "try:\n",
                "  response = session.get(url, params=parameters)\n",
                "  data = json.loads(response.text)\n",
                "except (ConnectionError, Timeout, TooManyRedirects) as e:\n",
                "  print(e)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "#get the current datetime to add to the file\n",
                "from datetime import datetime\n",
                "now = datetime.now()\n",
                "injest_date = now.strftime(\"%m/%d/%Y %H:%M:%S\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "#grabs section of dictionary \n",
                "cmc_data = data['data']\n",
                "#puts the dict into a DF, now need to expand nested platform column\n",
                "cmc_df = pd.DataFrame.from_dict(cmc_data, orient='columns')\n",
                "#expanded Datafram\n",
                "full_df = pd.concat([cmc_df.drop(['platform'], axis= 1), cmc_df['platform'].apply(pd.Series)], axis= 1 )\n",
                "#add column file name\n",
                "full_df[\"File_Name\"] = \"Coin_Ranking_Dim\"\n",
                "#Add column for injested at \n",
                "full_df[\"injest_datetime\"] = injest_date\n",
                "full_df.head()\n",
                "\n",
                "#turn dataframe to CSV\n",
                "full_df_CSV = full_df.to_csv()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                " - write DF to parquet format\n",
                " `trial_write_to_parquet = test.to_parquet(headers = 'none')`\n",
                " - write DF to CSV format\n",
                "`dfasCSV = test.to_csv()`\n",
                " - write DF to string format\n",
                "`dfAsString = test.to_string(header=False, index=False)`\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'date': datetime.datetime(2022, 3, 29, 22, 45, 18, tzinfo=datetime.timezone.utc),\n",
                            " 'etag': '\"0x8DA11D5CCE697B4\"',\n",
                            " 'last_modified': datetime.datetime(2022, 3, 29, 22, 45, 18, tzinfo=datetime.timezone.utc),\n",
                            " 'content_length': 0,\n",
                            " 'client_request_id': 'e89e31bd-afb1-11ec-b623-74d83ee76d90',\n",
                            " 'request_id': '1a01c476-101f-0058-57be-43e979000000',\n",
                            " 'version': '2020-10-02'}"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#this works, needed to send it as text !!\n",
                "#it works too, had to save it as a CSV\n",
                "from azure.storage.filedatalake import DataLakeServiceClient\n",
                "# install the following package \n",
                "# pip install azure-storage-file-datalake \n",
                "# Get the below details from your storage account\n",
                "storage_account_name = config.storage_account_name\n",
                "storage_account_key = config.storage_account_key\n",
                "container_name = config.container_name\n",
                "directory_name = config.directory_name\n",
                "\n",
                "service_client = DataLakeServiceClient(account_url=\"{}://{}.dfs.core.windows.net\".format(\n",
                "        \"https\", storage_account_name), credential=storage_account_key)\n",
                "\n",
                "file_system_client = service_client.get_file_system_client(file_system=container_name)\n",
                "dir_client = file_system_client.get_directory_client(directory_name)\n",
                "dir_client.create_directory()\n",
                "#set data to appropriate dataframe\n",
                "data = full_df_CSV \n",
                "\n",
                "\n",
                "#make sure to change file type as well\n",
                "file_client = dir_client.create_file(\"sampledata2.csv\")\n",
                "file_client.append_data(data, 0, len(data))\n",
                "file_client.flush_data(len(data))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### -----------------------------------------------------------------------------------------------------------------------------------------"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "ename": "AttributeError",
                    "evalue": "module 'config' has no attribute 'march29connectString'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
                        "\u001b[1;32mC:\\Users\\NICHOL~1.RAD\\AppData\\Local\\Temp/ipykernel_11680/4222583001.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Read CSV file from ADLS,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#clean up file and then write it back to storage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmarch29connectString\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mservice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLakeServiceClient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_connection_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn_str\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmarch29connectString\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;31mAttributeError\u001b[0m: module 'config' has no attribute 'march29connectString'"
                    ]
                }
            ],
            "source": [
                "#Read CSV file from ADLS,\n",
                "#clean up file and then write it back to storage\n",
                "service = DataLakeServiceClient.from_connection_string(conn_str= config.march29connectString)\n",
                "\n",
                "file = DataLakeFileClient.from_connection_string(\"config.march29connectString\",\n",
                "                                                 file_system_name=\"myfilesystem\", file_path=\"myfile\")\n",
                "\n",
                "with open(\"./BlockDestination.txt\", \"wb\") as my_file:\n",
                "    download = file.download_file()\n",
                "    download.readinto(my_file)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "58a687088a3261ce9df5dee3177c51a1c9f11335b27c4c9154772790953dd213"
        },
        "kernelspec": {
            "display_name": "Python 3.9.7 ('base')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
